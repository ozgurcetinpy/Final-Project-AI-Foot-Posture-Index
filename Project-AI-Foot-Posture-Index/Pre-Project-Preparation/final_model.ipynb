{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = r\"C:\\Users\\ozgur\\Desktop\\Final Project\\Bitirme Projesi\\Fotoğraflar\"\n",
    "spectrogram_folder = os.path.join(project_folder, '5_height_and_congruence_of_the_medial_longitudinal_arch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "dataset = []\n",
    "\n",
    "def get_images_labels(file_folder):\n",
    "  for root, directory, filenames in os.walk(file_folder):\n",
    "    for filename in filenames:\n",
    "      if filename.endswith(\"jpg\"):\n",
    "        read_images = cv2.imread(os.path.join(root, filename), 1)  # 0: cv2.IMREAD_GRAYSCALE; 1: cv2.IMREAD_COLOR; -1: cv2.IMREAD_UNCHANGED    \n",
    "        if(type(read_images) == type(None)):\n",
    "          pass\n",
    "        else:\n",
    "          read_images = cv2.resize(read_images, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_AREA)                                      \n",
    "        # read_images = cv2.resize(read_images, dsize=(IMG_WIDTH, IMG_HEIGHT),interpolation=cv2.INTER_AREA)  # resizing; interpolation=cv2.INTER_AREA\n",
    "        read_images = cv2.cvtColor(read_images, cv2.COLOR_BGR2GRAY)  #grayscaling\n",
    "        label_name = os.path.basename(root)\n",
    "        grayscale_images = read_images / 255  # normalizing\n",
    "        dataset.append([grayscale_images, label_name])\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_labels(file_folder):\n",
    "  for root, directory, filenames in os.walk(file_folder):\n",
    "    for filename in filenames:\n",
    "      if filename.endswith(\"jpg\"):\n",
    "        read_images = cv2.imread(os.path.join(root, filename), 1)  # 0: cv2.IMREAD_GRAYSCALE; 1: cv2.IMREAD_COLOR; -1: cv2.IMREAD_UNCHANGED    \n",
    "        if(type(read_images) == type(None)):\n",
    "          pass\n",
    "        else:\n",
    "          read_images = cv2.resize(read_images, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_AREA)   \n",
    "          \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_images_labels(spectrogram_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_preprocessing():\n",
    "  encoder = LabelEncoder()\n",
    "  obj_data = get_images_labels(spectrogram_folder)\n",
    "\n",
    "  image_data = np.array([obj_data[image_loc][0] for image_loc in range(len(obj_data))])\n",
    "  image_data = image_data.reshape(image_data.shape[0], image_data.shape[1], image_data.shape[2], 1)\n",
    "\n",
    "  label_data = np.array([obj_data[image_loc][1] for image_loc in range(len(obj_data))])\n",
    "  label_data = encoder.fit_transform(label_data)\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(image_data, label_data, train_size=0.75, random_state=42)\n",
    "\n",
    "  X_val = X_train[40:]\n",
    "  y_val = y_train[40:]\n",
    "  X_train = X_train[:6460]\n",
    "  y_train = y_train[:6460]\n",
    "\n",
    "  return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train, x_test, x_val, y_train, y_test, y_val \u001b[39m=\u001b[39m data_preprocessing()\n",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m, in \u001b[0;36mdata_preprocessing\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m obj_data \u001b[39m=\u001b[39m get_images_labels(spectrogram_folder)\n\u001b[0;32m      9\u001b[0m image_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([obj_data[image_loc][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m image_loc \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(obj_data))])\n\u001b[1;32m---> 10\u001b[0m image_data \u001b[39m=\u001b[39m image_data\u001b[39m.\u001b[39mreshape(image_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], image_data\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], image_data\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], \u001b[39m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m label_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([obj_data[image_loc][\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m image_loc \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(obj_data))])\n\u001b[0;32m     13\u001b[0m label_data \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mfit_transform(label_data)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "x_train, x_test, x_val, y_train, y_test, y_val = data_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, x_val.shape)\n",
    "print(y_train.shape, y_val.shape)\n",
    "\n",
    "# Print the lengths of the each dataset\n",
    "print(f\"\\nX_train: {len(x_train)}\")\n",
    "print(f\"y_train: {len(y_train)}\")\n",
    "print(f\"X_val: {len(x_val)}\")\n",
    "print(f\"y_val: {len(y_val)}\")\n",
    "print(f\"x_test: {len(x_test)}\")\n",
    "print(f\"y_test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import Sequential,optimizers\n",
    "\n",
    "\n",
    "def create_model(kernel_size: tuple, input_shape: tuple):\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(IMG_WIDTH,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(1,1),\n",
    "                  padding=\"same\",\n",
    "                  activation=\"relu\",\n",
    "                  input_shape=input_shape)           \n",
    "  )\n",
    "  model.add(MaxPooling2D((2,2)))\n",
    "  model.add(Conv2D(IMG_WIDTH,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(1,1),\n",
    "                  padding=\"same\",\n",
    "                  activation=\"relu\",\n",
    "                  input_shape=input_shape)           \n",
    "  )\n",
    "  model.add(MaxPooling2D((2,2)))\n",
    "  model.add(Conv2D(IMG_WIDTH/2,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(1,1),\n",
    "                  padding=\"same\",\n",
    "                  activation=\"relu\",\n",
    "                  input_shape=input_shape)           \n",
    "  )\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(64, activation='relu')),\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "  model.compile(optimizer=optimizers.Adadelta(lr=0.0001), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = create_model((3, 3), (IMG_WIDTH, IMG_HEIGHT, 1))\n",
    "results = my_model.fit(x_train, y_train,\n",
    "                    epochs=600,\n",
    "                    batch_size=16,\n",
    "                    validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results.history[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.plot(results.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(results.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance\n",
    "my_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(r'C:\\Users\\ozgur\\Desktop\\Final Project\\Bitirme Projesi\\model\\model_90_32_adam_000005.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mozgur\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFinal Project\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBitirme Projesi\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFotoğraflar\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m5_height_and_congruence_of_the_medial_longitudinal_arch\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2_1.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(image)\n\u001b[1;32m----> 3\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mfoto\u001b[39m\u001b[39m\"\u001b[39m,image\u001b[39m/\u001b[39;49m\u001b[39m255\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(r\"C:\\Users\\ozgur\\Desktop\\Final Project\\Bitirme Projesi\\Fotoğraflar\\5_height_and_congruence_of_the_medial_longitudinal_arch\\2\\2_1.jpg\")\n",
    "image = np.array(image)\n",
    "cv2.imshow(\"foto\",image/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     read_images \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(frame, (IMG_WIDTH, IMG_HEIGHT), interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_AREA) \n\u001b[1;32m----> 7\u001b[0m rgb_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(read_images,cv2\u001b[39m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[0;32m      8\u001b[0m normalized \u001b[39m=\u001b[39m rgb_image \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[0;32m      9\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray([normalized]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_images' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "frame = cv2.imread(r\"C:\\Users\\ozgur\\Desktop\\Final Project\\Bitirme Projesi\\Fotoğraflar\\5_height_and_congruence_of_the_medial_longitudinal_arch\\2\\2_1.jpg\")\n",
    "\n",
    "if(type(frame) == type(None)):\n",
    "          pass\n",
    "else:\n",
    "    read_images = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_AREA) \n",
    "rgb_image = cv2.cvtColor(read_images,cv2.COLOR_RGB2GRAY)\n",
    "normalized = rgb_image / 255.0\n",
    "result = model.predict(np.array([normalized]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 532ms/step\n",
      "[[2.4629719e-06 5.2318583e-06 2.6824096e-01 5.4766625e-01 1.8408506e-01\n",
      "  8.2000655e-09 2.8203160e-09 9.6293676e-12 1.6754395e-10 3.2502776e-09]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[[5.8633144e-05 5.9531434e-05 4.5258048e-01 4.0526247e-01 1.4203817e-01\n",
      "  4.2484336e-07 1.7257109e-07 3.4184984e-09 2.0327242e-08 1.7373426e-07]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[9.5105454e-05 8.5582382e-05 3.8824290e-01 4.3492734e-01 1.7664747e-01\n",
      "  8.3004591e-07 3.6900323e-07 7.9558049e-09 5.2034743e-08 3.6267070e-07]]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "[[9.9614539e-05 8.7780005e-05 4.0665105e-01 4.2614183e-01 1.6701806e-01\n",
      "  8.5797296e-07 3.7820985e-07 8.5986667e-09 5.3481070e-08 3.6910211e-07]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[1.06515006e-04 9.04819535e-05 4.00976896e-01 4.28870708e-01\n",
      "  1.69953600e-01 9.19021033e-07 4.09854181e-07 9.43281808e-09\n",
      "  5.94438099e-08 3.96710476e-07]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[[1.13676346e-04 9.51976035e-05 4.10682827e-01 4.22993958e-01\n",
      "  1.66112378e-01 1.00081365e-06 4.45091160e-07 1.08196305e-08\n",
      "  6.63564421e-08 4.34690264e-07]]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[1.16260315e-04 9.43107952e-05 4.20503199e-01 4.18284595e-01\n",
      "  1.60999700e-01 1.01873388e-06 4.47547251e-07 1.13380896e-08\n",
      "  6.99560374e-08 4.44059793e-07]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[1.03708146e-04 8.54928730e-05 4.43426758e-01 4.07462090e-01\n",
      "  1.48920253e-01 8.77265109e-07 3.72649566e-07 9.49131440e-09\n",
      "  5.81919437e-08 3.79252214e-07]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[9.9245706e-05 8.2083061e-05 4.6622741e-01 3.9551589e-01 1.3807374e-01\n",
      "  8.2735437e-07 3.4264167e-07 9.0455456e-09 5.4102738e-08 3.5520935e-07]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[8.5915628e-05 7.0715621e-05 5.0426197e-01 3.7505174e-01 1.2052846e-01\n",
      "  6.5683344e-07 2.6112880e-07 7.0173458e-09 4.0643449e-08 2.7763897e-07]]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "[[8.8842324e-05 7.3625204e-05 5.0284988e-01 3.7515745e-01 1.2182879e-01\n",
      "  6.9173643e-07 2.7701100e-07 7.5055988e-09 4.2872376e-08 2.9378867e-07]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[8.0227888e-05 6.6853965e-05 5.1633114e-01 3.6903128e-01 1.1448934e-01\n",
      "  6.0390551e-07 2.3594920e-07 6.3798997e-09 3.7074361e-08 2.5619789e-07]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "[[9.0717280e-05 7.1773677e-05 4.6834537e-01 3.9622474e-01 1.3526605e-01\n",
      "  7.1846341e-07 2.9516428e-07 7.5306739e-09 4.9190525e-08 3.1401683e-07]]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[1.0368916e-04 8.0025202e-05 3.9539164e-01 4.3505216e-01 1.6937079e-01\n",
      "  8.6341981e-07 3.8977922e-07 8.8500949e-09 6.4247516e-08 3.8871312e-07]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "[[1.11977155e-04 8.55650360e-05 3.89931053e-01 4.35552657e-01\n",
      "  1.74316868e-01 9.45584304e-07 4.30330090e-07 9.94111016e-09\n",
      "  7.04731704e-08 4.25971734e-07]]\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "[[1.2413083e-04 9.4763949e-05 3.5614315e-01 4.4876423e-01 1.9487147e-01\n",
      "  1.0993786e-06 5.2973138e-07 1.1703838e-08 8.5140371e-08 5.0946153e-07]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "[[1.12310096e-04 8.58442436e-05 4.17755306e-01 4.19998527e-01\n",
      "  1.62046120e-01 9.35272283e-07 4.18616082e-07 1.01713749e-08\n",
      "  6.82609809e-08 4.23384591e-07]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[1.16414194e-04 8.63322639e-05 4.24352080e-01 4.18205410e-01\n",
      "  1.57237828e-01 9.72384896e-07 4.34785363e-07 1.09565610e-08\n",
      "  7.38752703e-08 4.38695480e-07]]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[1.0944851e-04 8.1898062e-05 4.4666028e-01 4.0760827e-01 1.4553839e-01\n",
      "  9.0309885e-07 3.9032736e-07 1.0188353e-08 6.7481864e-08 4.0203386e-07]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[1.2531802e-04 9.5288378e-05 3.9304909e-01 4.3233153e-01 1.7439659e-01\n",
      "  1.1134636e-06 5.1047988e-07 1.2502673e-08 8.5607709e-08 5.0578177e-07]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "[[1.2433168e-04 9.4493327e-05 3.7452224e-01 4.4163460e-01 1.8362209e-01\n",
      "  1.1056864e-06 5.1891760e-07 1.2103272e-08 8.6078792e-08 5.0636686e-07]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "[[1.27198175e-04 1.00781370e-04 2.79076636e-01 4.81697172e-01\n",
      "  2.38995597e-01 1.27045178e-06 6.69211033e-07 1.27320980e-08\n",
      "  1.07106644e-07 6.08881521e-07]]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[1.2749838e-04 1.0299229e-04 2.6422289e-01 4.8600316e-01 2.4954060e-01\n",
      "  1.3389051e-06 7.2124573e-07 1.3355802e-08 1.1379281e-07 6.5551529e-07]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[1.1342190e-04 9.7187221e-05 2.2398996e-01 4.9951422e-01 2.7628249e-01\n",
      "  1.2860600e-06 7.1989950e-07 1.1765464e-08 1.1000604e-07 6.6138466e-07]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[1.21409954e-04 1.02389451e-04 2.25671381e-01 4.98033673e-01\n",
      "  2.76068211e-01 1.39722533e-06 7.86910562e-07 1.32800073e-08\n",
      "  1.21997758e-07 7.20065202e-07]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[1.24539787e-04 1.04125480e-04 2.39907861e-01 4.94295448e-01\n",
      "  2.65564948e-01 1.41218857e-06 7.77835282e-07 1.37102365e-08\n",
      "  1.22106556e-07 7.09249036e-07]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[1.21965364e-04 1.03715698e-04 2.34141573e-01 4.95292127e-01\n",
      "  2.70337701e-01 1.40046438e-06 7.78412755e-07 1.34118388e-08\n",
      "  1.20619902e-07 7.13175609e-07]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[1.19887627e-04 9.80945988e-05 2.47829556e-01 4.95240718e-01\n",
      "  2.56709039e-01 1.30274748e-06 6.99116299e-07 1.24132615e-08\n",
      "  1.11647680e-07 6.33488241e-07]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[[1.2468219e-04 1.0208603e-04 2.4275950e-01 4.9473700e-01 2.6227379e-01\n",
      "  1.3828462e-06 7.5713916e-07 1.3424406e-08 1.1999232e-07 6.8639679e-07]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[3.0612468e-04 2.6068659e-04 2.8760895e-01 4.4628644e-01 2.6552668e-01\n",
      "  4.7989779e-06 2.8945365e-06 7.8683456e-08 4.7404023e-07 2.7993206e-06]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[7.5672637e-04 5.8380223e-04 4.6532747e-01 3.5706607e-01 1.7623506e-01\n",
      "  1.3322169e-05 7.7199629e-06 4.2998170e-07 1.3474637e-06 8.0936079e-06]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "[[5.5513380e-04 4.2657397e-04 5.0403994e-01 3.4637979e-01 1.4858030e-01\n",
      "  8.2025426e-06 4.4894946e-06 2.3631375e-07 7.4257980e-07 4.5253751e-06]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[[4.6941513e-04 3.7011746e-04 5.5307537e-01 3.2523066e-01 1.2084059e-01\n",
      "  6.3665284e-06 3.3272424e-06 1.8349149e-07 5.3847174e-07 3.3676638e-06]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Kameradan bir kare alın\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Görüntüyü boyutlandırın ve normalize edin\n",
    "\n",
    "    resized = cv2.resize(frame, (64,64))\n",
    "    rgb_image = cv2.cvtColor(resized,cv2.COLOR_RGB2GRAY)\n",
    "    normalized = rgb_image / 255.0\n",
    "\n",
    "    # Görüntüyü modele girdi olarak sağlayın\n",
    "    result = model.predict(np.array([normalized]))\n",
    "    print(result)\n",
    "    # En yüksek olasılığa sahip sınıfı bulun\n",
    "    predicted_class = np.argmax(result[0])\n",
    "    \n",
    "    # Sınıf etiketlerini yükleyin\n",
    "    class_labels = [\"5\",\"4\",\"3\",\"2\",\"1\"]\n",
    "    # print(predicted_class)\n",
    "    # Sınıf etiketini yazdırın\n",
    "    label = class_labels[predicted_class]\n",
    "    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    # Görüntüyü gösterin\n",
    "    cv2.imshow(\"Kamera\", frame)\n",
    "\n",
    "    # Çıkış için 'q' tuşuna basın\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Kamerayı serbest bırakın ve pencereyi kapatın\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
