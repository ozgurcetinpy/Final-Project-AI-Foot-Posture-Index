{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import torchvision\n",
    "import yaml\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6 SaÄŸ Ayak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x320 1 0, 587.1ms\n",
      "Speed: 2.0ms preprocess, 587.1ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "\n",
      "0: 224x192 1 2, 197.5ms\n",
      "Speed: 1.0ms preprocess, 197.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.yolo.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[ 32.8943,  90.5165, 117.1175, 156.2940,   0.4538,   2.0000]])\n",
      "cls: tensor([2.])\n",
      "conf: tensor([0.4538])\n",
      "data: tensor([[ 32.8943,  90.5165, 117.1175, 156.2940,   0.4538,   2.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: tensor([159, 120])\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 75.0059, 123.4052,  84.2231,  65.7775]])\n",
      "xywhn: tensor([[0.6250, 0.7761, 0.7019, 0.4137]])\n",
      "xyxy: tensor([[ 32.8943,  90.5165, 117.1175, 156.2940]])\n",
      "xyxyn: tensor([[0.2741, 0.5693, 0.9760, 0.9830]])\n",
      "2\n",
      "diff -103\n",
      "class_name:  2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_yolov8x = YOLO(r\"C:\\Users\\ozgur\\Bitirme\\models\\weights_seg.pt\")\n",
    "model_yolov8x_heel = YOLO(r\"C:\\Users\\ozgur\\Bitirme\\models\\weights_4_776.pt\")\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\ozgur\\Bitirme\\YoloV8\\YoloV8\\all_photos_cutted_resized\\Model_2\\-2\\-2_8.jpeg\")\n",
    "\n",
    "results = model_yolov8x(img)\n",
    "results_heel = model_yolov8x_heel(img)\n",
    "result = results[0]\n",
    "result_heel = results_heel[0]\n",
    "masks = result.masks.xy\n",
    "mask = masks[0]\n",
    "print(result_heel.boxes)\n",
    "cls = str(int(result_heel.boxes.cls[0]))\n",
    "\n",
    "poly = np.array(mask, np.int32)\n",
    "poly = poly.reshape((-1, 1, 2))\n",
    "cv2.fillPoly(img, [poly], (255,255,0))\n",
    "\n",
    "points = poly.squeeze()\n",
    "highest_points = points[points[:, 1] == np.min(points[:, 1])]\n",
    "center_point = np.mean(highest_points, axis=0).astype(int)\n",
    "bottom_mask = mask[mask[:, 1] >= center_point[1]]\n",
    "bottom_left_pixels = len(bottom_mask[bottom_mask[:, 0] < center_point[0]])\n",
    "bottom_right_pixels = len(bottom_mask[bottom_mask[:, 0] >= center_point[0]])\n",
    "diff = bottom_right_pixels-bottom_left_pixels\n",
    "\n",
    "print(cls)\n",
    "print(\"diff\",diff)\n",
    "\n",
    "\n",
    "if cls == '2':\n",
    "    class_name = '2'\n",
    "elif cls == '4':\n",
    "    class_name = '-2'\n",
    "else:\n",
    "    if diff < 250 and diff >= 40:\n",
    "        class_name = '1'\n",
    "    elif diff < 40 and diff >= -40:\n",
    "        class_name = '0'\n",
    "    elif diff < -40 and diff >= -250:\n",
    "        class_name = '-1'\n",
    "    \n",
    "\n",
    "print(\"class_name: \",class_name)\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x512 1 -1, 1 -2, 1056.0ms\n",
      "Speed: 3.0ms preprocess, 1056.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 416x320 1 0, 573.3ms\n",
      "Speed: 1.0ms preprocess, 573.3ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.yolo.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[  3.6379,  18.7973, 120.0000, 159.0000,   0.6451,   3.0000],\n",
      "        [  3.2639,  16.1345, 120.0000, 158.8915,   0.3068,   4.0000]])\n",
      "cls: tensor([3., 4.])\n",
      "conf: tensor([0.6451, 0.3068])\n",
      "data: tensor([[  3.6379,  18.7973, 120.0000, 159.0000,   0.6451,   3.0000],\n",
      "        [  3.2639,  16.1345, 120.0000, 158.8915,   0.3068,   4.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: tensor([159, 120])\n",
      "shape: torch.Size([2, 6])\n",
      "xywh: tensor([[ 61.8190,  88.8986, 116.3621, 140.2027],\n",
      "        [ 61.6320,  87.5130, 116.7361, 142.7570]])\n",
      "xywhn: tensor([[0.5152, 0.5591, 0.9697, 0.8818],\n",
      "        [0.5136, 0.5504, 0.9728, 0.8978]])\n",
      "xyxy: tensor([[  3.6379,  18.7973, 120.0000, 159.0000],\n",
      "        [  3.2639,  16.1345, 120.0000, 158.8915]])\n",
      "xyxyn: tensor([[0.0303, 0.1182, 1.0000, 1.0000],\n",
      "        [0.0272, 0.1015, 1.0000, 0.9993]])\n",
      "3\n",
      "diff 46\n",
      "class_name:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_yolov8x = YOLO(r\"C:\\Users\\ozgur\\Bitirme\\models\\weights_2_63.pt\")\n",
    "model_yolov8x_seg = YOLO(r\"C:\\Users\\ozgur\\Bitirme\\models\\weights_seg.pt\")\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\ozgur\\Bitirme\\YoloV8\\YoloV8\\all_photos_cutted_resized\\Model_2\\-2\\-2_8.jpeg\")\n",
    "\n",
    "results = model_yolov8x(img)\n",
    "results_seg = model_yolov8x_seg(img)\n",
    "result = results[0]\n",
    "result_seg = results_seg[0]\n",
    "masks = result_seg.masks.xy\n",
    "mask = masks[0]\n",
    "print(result.boxes)\n",
    "cls = str(int(result.boxes.cls[0]))\n",
    "\n",
    "poly = np.array(mask, np.int32)\n",
    "poly = poly.reshape((-1, 1, 2))\n",
    "cv2.fillPoly(img, [poly], (255,255,0))\n",
    "\n",
    "points = poly.squeeze()\n",
    "highest_points = points[points[:, 1] == np.min(points[:, 1])]\n",
    "center_point = np.mean(highest_points, axis=0).astype(int)\n",
    "bottom_mask = mask[mask[:, 1] >= center_point[1]]\n",
    "bottom_left_pixels = len(bottom_mask[bottom_mask[:, 0] < center_point[0]])\n",
    "bottom_right_pixels = len(bottom_mask[bottom_mask[:, 0] >= center_point[0]])\n",
    "diff = bottom_right_pixels-bottom_left_pixels\n",
    "\n",
    "print(cls)\n",
    "print(\"diff\",diff)\n",
    "\n",
    "\n",
    "if cls == '2':\n",
    "    class_name = '2'\n",
    "elif cls == '4':\n",
    "    class_name = '-2'\n",
    "else:\n",
    "    if diff >= 40:\n",
    "        class_name = '1'\n",
    "    elif diff < 40 and diff >= -40:\n",
    "        class_name = '0'\n",
    "    elif diff < -40:\n",
    "        class_name = '-1'\n",
    "    \n",
    "\n",
    "print(\"class_name: \",class_name)\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 224x192 1 -1, 210.4ms\n",
      "Speed: 0.0ms preprocess, 210.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.yolo.engine.results.Boxes object with attributes:\n",
      "\n",
      "boxes: tensor([[  0.8478,  16.1531, 118.0108, 158.6274,   0.9745,   3.0000]])\n",
      "cls: tensor([3.])\n",
      "conf: tensor([0.9745])\n",
      "data: tensor([[  0.8478,  16.1531, 118.0108, 158.6274,   0.9745,   3.0000]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: tensor([159, 120])\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[ 59.4293,  87.3903, 117.1631, 142.4744]])\n",
      "xywhn: tensor([[0.4952, 0.5496, 0.9764, 0.8961]])\n",
      "xyxy: tensor([[  0.8478,  16.1531, 118.0108, 158.6274]])\n",
      "xyxyn: tensor([[0.0071, 0.1016, 0.9834, 0.9977]])\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_yolov8x_4 = YOLO(r\"C:\\Users\\ozgur\\Bitirme\\models\\weights_2_629.pt\")\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\ozgur\\Bitirme\\YoloV8\\YoloV8\\all_photos_cutted_resized\\Model_2\\-2\\-2_8.jpeg\")\n",
    "\n",
    "results = model_yolov8x_4(img)\n",
    "result = results[0]\n",
    "print(result.boxes)\n",
    "cls = str(int(result.boxes.cls[0]))\n",
    "\n",
    "if cls == '2':\n",
    "    class_name = '2'\n",
    "elif cls == '4':\n",
    "    class_name = '2'\n",
    "elif cls == '1':\n",
    "    class_name = '1'\n",
    "elif cls == '0':\n",
    "    class_name = '0'\n",
    "elif cls == '3':\n",
    "    class_name = '-1'\n",
    "\n",
    "print(class_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
